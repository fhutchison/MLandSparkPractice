{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e96b346-83d0-4603-bcab-670459c3baa2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "![ecommerce_analytics-1224x532](ecommerce_analytics-1224x532.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5bc4a615-dffa-40ae-9dd3-9468aa61f3bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "collapsed": false
   },
   "source": [
    "As a Data Engineer at an electronics e-commerce company, Voltmart, you have been requested by a peer Machine Learning team to clean the data containing the information about orders made last year. They are planning to further use this cleaned data to build a demand forecasting model. To achieve this, they have shared their requirements regarding the desired output table format.\n",
    "\n",
    "An analyst shared a parquet file called `\"orders_data.parquet\"` for you to clean and preprocess. \n",
    "\n",
    "You can see the dataset schema below along with the **cleaning requirements**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e21b3f92-7eb8-404d-9b04-05ab1df09716",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## `orders_data.parquet`\n",
    "\n",
    "| column | data type | description | cleaning requirements | \n",
    "|--------|-----------|-------------|-----------------------|\n",
    "| `order_date` | `timestamp` | Date and time when the order was made | _Modify: Remove orders placed between 12am and 5am (inclusive); convert from timestamp to date_ |\n",
    "| `time_of_day` | `string` | Period of the day when the order was made | _New column containing (lower bound inclusive, upper bound exclusive): \"morning\" for orders placed 5-12am, \"afternoon\" for orders placed 12-6pm, and \"evening\" for 6-12pm_ |\n",
    "| `order_id` | `long` | Order ID | _N/A_ |\n",
    "| `product` | `string` | Name of a product ordered | _Remove rows containing \"TV\" as the company has stopped selling this product; ensure all values are lowercase_ |\n",
    "| `product_ean` | `double` | Product ID | _N/A_ |\n",
    "| `category` | `string` | Broader category of a product | _Ensure all values are lowercase_ |\n",
    "| `purchase_address` | `string` | Address line where the order was made (\"House Street, City, State Zipcode\") | _N/A_ |\n",
    "| `purchase_state` | `string` | US State of the purchase address | _New column containing: the State that the purchase was ordered from_ |\n",
    "| `quantity_ordered` | `long` | Number of product units ordered | _N/A_ |\n",
    "| `price_each` | `double` | Price of a product unit | _N/A_ |\n",
    "| `cost_price` | `double` | Cost of production per product unit | _N/A_ |\n",
    "| `turnover` | `double` | Total amount paid for a product (quantity x price) | _N/A_ |\n",
    "| `margin` | `double` | Profit made by selling a product (turnover - cost) | _N/A_ |\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba4ec245-8cfe-4ecd-87fa-d7207f406849",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "executionCancelledAt": null,
    "executionTime": 49,
    "lastExecutedAt": 1760633837461,
    "lastExecutedByKernel": "42f76163-548f-47a0-8e95-05ea20d71d25",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "from pyspark.sql import (\n    SparkSession,\n    types,\n    functions as F,\n)\n\nspark = (\n    SparkSession\n    .builder\n    .appName('cleaning_orders_dataset_with_pyspark')\n    .getOrCreate()\n)",
    "outputsMetadata": {
     "0": {
      "height": 59,
      "type": "stream"
     },
     "1": {
      "height": 59,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import (\n",
    "    SparkSession,\n",
    "    types,\n",
    "    functions as F,\n",
    ")\n",
    "\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName('cleaning_orders_dataset_with_pyspark')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef0f52e5-5177-4a60-863e-2900088f03eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "executionCancelledAt": null,
    "executionTime": 2641,
    "lastExecutedAt": 1760633840102,
    "lastExecutedByKernel": "42f76163-548f-47a0-8e95-05ea20d71d25",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "orders_data = spark.read.parquet('orders_data.parquet')\norders_data.toPandas().head()",
    "outputsMetadata": {
     "0": {
      "height": 550,
      "tableState": {},
      "type": "dataFrame"
     },
     "1": {
      "height": 500,
      "tableState": {},
      "type": "dataFrame"
     }
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.cp(\n",
    "    \"file:/Workspace/Repos/mrfrankhutch04@gmail.com/MLandSparkPractice/Data File Storage/orders_data.parquet\",\n",
    "    \"dbfs:/FileStore/orders_data.parquet\"\n",
    ")\n",
    "\n",
    "# Then read from DBFS\n",
    "orders_data = spark.read.parquet(\"/FileStore/orders_data.parquet\")\n",
    "orders_data.toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c2442842-4fca-4a0b-b9f0-efb62992f57d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "1. Filters TV out of products and lowercases the product and category columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "91d31953-2134-4d64-bbbf-f7aab081838a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "executionCancelledAt": null,
    "executionTime": 2618,
    "lastExecutedAt": 1760633842720,
    "lastExecutedByKernel": "42f76163-548f-47a0-8e95-05ea20d71d25",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Start here, using as many cells as you require\nod = orders_data.withColumn('product', F.lower('product')) \\\n.where(~F.col('product').contains('tv')) \\\n.withColumn('category', F.lower('category'))\nod.toPandas().head()",
    "outputsMetadata": {
     "0": {
      "height": 550,
      "tableState": {},
      "type": "dataFrame"
     }
    }
   },
   "outputs": [],
   "source": [
    "# Start here, using as many cells as you require\n",
    "od = orders_data.withColumn('product', F.lower('product')) \\\n",
    ".where(~F.col('product').contains('tv')) \\\n",
    ".withColumn('category', F.lower('category'))\n",
    "od.toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "49aaa59a-b7e1-436e-8f43-88e1ca8f3e4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "2. Create column of state where order made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "66e749c8-f844-4a65-86f5-77cc7fbdd72e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "executionCancelledAt": null,
    "executionTime": 2757,
    "lastExecutedAt": 1760633845477,
    "lastExecutedByKernel": "42f76163-548f-47a0-8e95-05ea20d71d25",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "od = od.withColumn('purchase_state', F.substring(F.col('purchase_address'), -8, 2))\nod.toPandas().head()",
    "outputsMetadata": {
     "0": {
      "height": 550,
      "tableState": {
       "customFilter": {
        "const": {
         "type": "boolean",
         "valid": true,
         "value": true
        },
        "id": "d30f4143-176d-4c29-a67e-04116222eaaa",
        "nodeType": "const"
       }
      },
      "type": "dataFrame"
     }
    }
   },
   "outputs": [],
   "source": [
    "od = od.withColumn('purchase_state', F.substring(F.col('purchase_address'), -8, 2))\n",
    "od.toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "18ee5192-31d1-4c02-8d57-d28f93058be1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "3. Split Time and Day and Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0e8087f8-333f-4877-807d-54dc411bbfbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "executionCancelledAt": null,
    "executionTime": 3185,
    "lastExecutedAt": 1760633848662,
    "lastExecutedByKernel": "42f76163-548f-47a0-8e95-05ea20d71d25",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "od = od.filter((F.hour('order_date').between(5, 23)) | (F.hour('order_date') == 0)) \\\n        .withColumn('time_of_day', F.when((F.hour('order_date')>=5) & (F.hour('order_date')<12), 'morning')\\\n             .when((F.hour('order_date')>=12) & (F.hour('order_date')<18), 'afternoon')\\\n             .otherwise('evening')) \\\n        .withColumn('order_date', F.to_date('order_date', 'YYYY-MM-DD'))\nod.toPandas().head()",
    "outputsMetadata": {
     "0": {
      "height": 550,
      "tableState": {},
      "type": "dataFrame"
     },
     "1": {
      "height": 500,
      "tableState": {},
      "type": "dataFrame"
     }
    },
    "version": "ag-charts-v1",
    "visualizeDataframe": false
   },
   "outputs": [],
   "source": [
    "od = od.filter((F.hour('order_date').between(5, 23)) | (F.hour('order_date') == 0)) \\\n",
    "        .withColumn('time_of_day', F.when((F.hour('order_date')>=5) & (F.hour('order_date')<12), 'morning')\\\n",
    "             .when((F.hour('order_date')>=12) & (F.hour('order_date')<18), 'afternoon')\\\n",
    "             .otherwise('evening')) \\\n",
    "        .withColumn('order_date', F.to_date('order_date', 'YYYY-MM-DD'))\n",
    "od.toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "760fe255-af5d-4846-b0d3-1a3e0f2d3217",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "4. Save file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ae51f8bf-84ea-44c8-b66e-6631345069ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "executionCancelledAt": null,
    "executionTime": 2986,
    "lastExecutedAt": 1760633851648,
    "lastExecutedByKernel": "42f76163-548f-47a0-8e95-05ea20d71d25",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "od.write.mode(\"overwrite\").save(\"orders_data_clean.parquet\")",
    "outputsMetadata": {
     "0": {
      "height": 38,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "od.write.mode(\"overwrite\").save(\"orders_data_clean.parquet\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Spark DataCamp Cleaning Project",
   "widgets": {}
  },
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "editor": "DataLab",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
