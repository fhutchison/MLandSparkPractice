{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1566d85f-2a6f-44bf-97a1-31efd0ed4a45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "WITH date_diffs AS (\n",
    "    SELECT \n",
    "        user_id,\n",
    "        purchase_date,\n",
    "        LAG(purchase_date, 1) OVER (PARTITION BY user_id ORDER BY purchase_date) AS prev_date_1,\n",
    "        LAG(purchase_date, 2) OVER (PARTITION BY user_id ORDER BY purchase_date) AS prev_date_2\n",
    "    FROM (\n",
    "        SELECT DISTINCT user_id, purchase_date  -- Remove duplicates on same day\n",
    "        FROM purchases\n",
    "    ) distinct_purchases\n",
    ")\n",
    "SELECT DISTINCT user_id\n",
    "FROM date_diffs\n",
    "WHERE \n",
    "    DATEDIFF(day, prev_date_2, prev_date_1) = 1\n",
    "    AND DATEDIFF(day, prev_date_1, purchase_date) = 1;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ac3bf0dc-0f0e-4234-a86a-2e093332f2f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "WITH monthly_revenue AS (\n",
    "    SELECT\n",
    "        product_category,\n",
    "        DATE_TRUNC('month', sale_date) AS month,  -- or DATE_FORMAT depending on your SQL dialect\n",
    "        SUM(revenue) AS monthly_revenue\n",
    "    FROM sales\n",
    "    GROUP BY product_category, DATE_TRUNC('month', sale_date)\n",
    "),\n",
    "with_previous AS (\n",
    "    SELECT\n",
    "        product_category,\n",
    "        month,\n",
    "        monthly_revenue,\n",
    "        LAG(monthly_revenue, 1) OVER (\n",
    "            PARTITION BY product_category \n",
    "            ORDER BY month\n",
    "        ) AS prev_month_revenue\n",
    "    FROM monthly_revenue\n",
    ")\n",
    "SELECT\n",
    "    product_category,\n",
    "    month,\n",
    "    monthly_revenue,\n",
    "    prev_month_revenue,\n",
    "    ROUND(\n",
    "        ((monthly_revenue - prev_month_revenue) / prev_month_revenue) * 100, \n",
    "        2\n",
    "    ) AS percent_change\n",
    "FROM with_previous\n",
    "WHERE prev_month_revenue IS NOT NULL  -- Exclude first month (no previous data)\n",
    "ORDER BY product_category, month;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e99f616-2a3e-4241-8e6c-f01c349b1810",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "WITH depo_sal AS (\n",
    "  SELECT\n",
    "  department_id, AVG(e.salary) AS avg_salary\n",
    "  FROM employees\n",
    "  GROUP BY department_id\n",
    ")\n",
    "\n",
    "SELECT e.name, e.department_name, e.salary, ds.avg_salary\n",
    "FROM employees e\n",
    "INNER JOIN departments d\n",
    "ON e.department_id = d.department_id\n",
    "INNER JOIN depo_sal ds\n",
    "ON e.department_id = ds.department_id\n",
    "WHERE e.salary > ds.avg_salary\n",
    "ORDER BY e.salary DESC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be2cdf63-ad16-4791-939c-ae7c8f0184b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "transactions = [\n",
    "    {'customer_id': 1, 'amount': 100, 'email': 'test@email.com'},\n",
    "    {'customer_id': 1, 'amount': 150, 'email': 'test\\email.com'},\n",
    "    { 'amount': 200, 'email': 'test@email.com'},\n",
    "    # ... more transactions\n",
    "]\n",
    "\n",
    "t1 = pd.DataFrame(transactions)\n",
    "pattern = r\"^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$\"\n",
    "print(~t1['email'].str.contains(pattern))\n",
    "\n",
    "\"\"\"**Q22.** Implement a data validation function that checks if a pandas DataFrame meets these requirements:\n",
    "# - No duplicate rows\n",
    "# - Column 'email' contains valid email format\n",
    "# - Column 'age' is between 0 and 120\n",
    "# - No missing values in 'user_id'\n",
    "\n",
    "Return a dictionary with validation results.\n",
    "\"\"\"\n",
    "\n",
    "def transactions_validation(df):\n",
    "    val_dict = {'Duplicated Rows': False, 'Invalid Emails': False, 'Age out of range': False, 'Missing User Id': False}\n",
    "    cleaned_df = df.copy()\n",
    "\n",
    "    if df!=df[~df.duplicated()]:\n",
    "        val_dict['Duplicated Rows'] = True\n",
    "        cleaned_df = cleaned_df.drop_duplicates()\n",
    "    \n",
    "    pattern = r\"^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$\"\n",
    "    if ~cleaned_df['email'].str.contains(pattern).any()==True:\n",
    "        val_dict['Invalid Email'] = True\n",
    "        cleaned_df = cleaned_df[cleaned_df['email'].str.contains(pattern)]\n",
    "\n",
    "    age_valid = (cleaned_df['age'] >= 0) & (cleaned_df['age'] <= 120)\n",
    "    if (~age_valid).any():\n",
    "        val_dict['Age out of range'] = True\n",
    "        cleaned_df = cleaned_df[age_valid]\n",
    "    \n",
    "    if df['user_id'].isna().any():\n",
    "        val_dict['Missing User Id'] = True\n",
    "        cleaned_df = cleaned_df[~cleaned_df['user_id'].isna()]\n",
    "    \n",
    "    return val_dict, cleaned_df\n",
    "\n",
    "\"\"\"\n",
    "**Q23.** Write a Python function that connects to a database, executes a query in chunks to avoid memory issues, and writes results to a CSV file incrementally. Use proper error handling and context managers.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a812f08-7f75-4b32-ba68-9b75abec29a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "--Problem: Show each employee with their department's average salary using subquery, join, & window function\n",
    "\n",
    "--Subquery\n",
    "SELECT c1.employee, c1.salary, (SELECT AVG(c2.salary) FROM company c2 WHERE c2.department=c1.department) AS depart_avg_sal\n",
    "FROM company c1;\n",
    "\n",
    "--Group By and Join\n",
    "SELECT c1.employee, c1.salary, c2.depart_avg_sal\n",
    "FROM company c1\n",
    "INNER JOIN (SELECT department, AVG(salary) AS depart_avg_sal FROM company c2 GROUP BY department) c2\n",
    "ON c2.department=c1.department;\n",
    "\n",
    "--Window Function\n",
    "SELECT employee, salary, AVG(salary) OVER (PARTITION BY department) AS depart_avg_sal\n",
    "FROM company;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2d187bb7-5118-47ff-8680-09a7213fedc9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "WITH daily_sales AS (\n",
    "  SELECT \n",
    "    p.category,\n",
    "    s.sale_date,\n",
    "    SUM(s.amount) AS daily_total\n",
    "  FROM sales s\n",
    "  INNER JOIN products p \n",
    "    ON p.product_id = s.product_id\n",
    "  GROUP BY p.category, s.sale_date\n",
    ")\n",
    "SELECT \n",
    "  category,\n",
    "  sale_date,\n",
    "  SUM(daily_total) OVER (\n",
    "    PARTITION BY category \n",
    "    ORDER BY sale_date\n",
    "  ) AS cumulative_sales\n",
    "FROM daily_sales\n",
    "ORDER BY category, sale_date;\n",
    "\n",
    "WITH user_months AS (\n",
    "  SELECT \n",
    "    user_id,\n",
    "    DATE_TRUNC('month', signup_date) AS signup_month\n",
    "  FROM users\n",
    "),\n",
    "login_months AS (\n",
    "  SELECT \n",
    "    user_id,\n",
    "    DATE_TRUNC('month', login_date) AS login_month\n",
    "  FROM logins\n",
    "),\n",
    "signup_counts AS (\n",
    "  SELECT signup_month, COUNT(DISTINCT user_id) AS signups\n",
    "  FROM user_months\n",
    "  GROUP BY signup_month\n",
    "),\n",
    "retained AS (\n",
    "  SELECT \n",
    "    u.signup_month,\n",
    "    COUNT(DISTINCT l.user_id) AS retained_users\n",
    "  FROM user_months u\n",
    "  JOIN login_months l\n",
    "    ON u.user_id = l.user_id\n",
    "   AND l.login_month = u.signup_month + INTERVAL '1 month'\n",
    "  GROUP BY u.signup_month\n",
    ")\n",
    "SELECT \n",
    "  r.signup_month,\n",
    "  r.retained_users,\n",
    "  s.signups,\n",
    "  ROUND(r.retained_users * 1.0 / s.signups, 4) AS retention_rate\n",
    "FROM retained r\n",
    "JOIN signup_counts s USING (signup_month)\n",
    "ORDER BY signup_month;\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Assessment Practice",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
